{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8019fc6b-f3e6-494a-b39d-5777ef41f61c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Welcome to Full Stack Machine Learning's Week 1 Project!\n",
    "\n",
    "Welcome to an exhilarating journey into the world of machine learning! This week, you're stepping into the shoes of a data scientist at ModaMetric, an eCommerce startup specializing in bespoke women's fashion. \n",
    "\n",
    "## The ModaMetric Journey\n",
    "\n",
    "ModaMetric is a budding star in the eCommerce landscape, gaining rapid popularity among customers for its unique and stylish fashion offerings. However, they've faced a bottleneck: understanding their customers' sentiments from the ocean of reviews and feedback they receive daily. Your role as a member of ModaMetric's data science team is pivotal in solving this issue. Your mission? To implement an effective sentiment analysis model that can sift through the plethora of customer reviews and provide actionable insights.\n",
    "\n",
    "## Your Role: A Pioneer Data Scientist at ModaMetric\n",
    "\n",
    "As ModaMetric's newly onboarded data scientist, you're entrusted with an exciting challenge. The data science team, still in its infancy, has primarily focused on metrics and analytics that provide surface-level insights. They've yet to delve into the rich, unstructured data residing in customer reviews. And that's where you step in. Your job is to design and implement a machine learning pipeline using Metaflow capable of performing sentiment analysis on the customer reviews.\n",
    " \n",
    "\n",
    "### Using GitHub\n",
    "\n",
    "To complete the assignment:\n",
    "1. Fill in the TODO sections of this notebook.\n",
    "2. Push the results to your `full-stack-ml-metaflow-corise-week-1` repository.\n",
    "3. Create a link to the repository in Corise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdf852-7657-438b-868d-9e3558d76fda",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747eb85-cb54-49cf-a10c-b5c9fe1b6f3f",
   "metadata": {},
   "source": [
    "You're starting with a [Women's Ecommerce Clothing Reviews Dataset from Kaggle](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews). This dataset closely mirrors the data that ModaMetric gathers. Your first task involves understanding the structure, variables, and potential quirks of this dataset. Remember, knowing your data is the first step in any data science project!\n",
    "\n",
    "Exploratory Data Analysis (EDA) is a critical step in the data science pipeline as it allows us to gain insights and identify patterns within the data. In this section, we will be performing EDA on the Women's Clothing E-Commerce dataset, which contains reviews written by customers. Through this process, we will be looking out for trends, anomalies, and outliers that can help us better understand the data and inform our decision-making in subsequent stages of the project. By performing EDA, we will be able to identify potential issues with the dataset and make necessary corrections before proceeding to the model building phase.\n",
    "\n",
    "Suggestion: Spend 1-2 hours on this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0c95a-43ba-4a5d-a1a1-dc1f9daa5308",
   "metadata": {},
   "source": [
    "### Import Dependencies\n",
    "You can change these if you wish! \n",
    "These packages are already installed in the `full-stack-metaflow-corise` environment. \n",
    "If you are feeling adventurous, you can install other packages you want in the conda environment too, or even make your own environment from scratch and include with your submission! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b61acf-4e53-4051-981b-24e84edb333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f94c87-4a0a-49b5-b87f-72b791c6eac2",
   "metadata": {},
   "source": [
    "### Configure plots\n",
    "This part is optional styling your plots and cards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de92beb-0f85-41bf-b40c-893df72a77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = \"#FFBC00\"\n",
    "GREEN = \"#37795D\"\n",
    "PURPLE = \"#5460C0\"\n",
    "BACKGROUND = \"#F4EBE6\"\n",
    "colors = [GREEN, PURPLE]\n",
    "custom_params = {\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.facecolor\": BACKGROUND,\n",
    "    \"figure.facecolor\": BACKGROUND,\n",
    "    \"figure.figsize\": (8, 8),\n",
    "}\n",
    "sns_palette = sns.color_palette(colors, len(colors))\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf607e7-7e2b-444a-8907-6e93c2f4d70d",
   "metadata": {},
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae743a20-9d18-4e1a-936c-027bbb707b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dataset, ensure to use index_col=0 when reading the CSV file.\n",
    "# Hints\n",
    "# Look in the ../../data directory of this worksapce.\n",
    "# hinkIf you use pandas t about the index_col arg 🧐\n",
    "df = pd.read_csv('../data/Womens Clothing E-Commerce Reviews.csv',index_col=0 )\n",
    "\n",
    "\n",
    "# light data cleaning\n",
    "df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "df[\"review_text\"] = df[\"review_text\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab17e4-22f3-4f91-adac-2d8662784466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1fa48-d32b-4107-a7b6-38aa612e9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd8bdf-f2ad-4e2f-be29-1dc84d7e37f6",
   "metadata": {},
   "source": [
    "### Plot the distribution of [1, 5] ratings\n",
    "\n",
    "We will be using the `rating` to create a label on this dataset. We can see that the mean rating is above 4, pretty happy customers!\n",
    "\n",
    "Let's try to visualise the distrbution of the label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdaed5-05fe-4f1a-81f2-d3c6231462be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Derive the rating_distribution and plot it\n",
    "rating_distribution = df['rating'].value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "# You can swap the color used with the defined constants at the top of the notebook\n",
    "ax.bar(x=rating_distribution.index, height=rating_distribution.values, color=GREEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0939472b-90ba-48bb-93a8-9c42ae0716d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling_function(row):\n",
    "    \"\"\"\n",
    "    A function to derive labels from the user's review data.\n",
    "    This could use many variables, or just one.\n",
    "    In supervised learning scenarios, this is a very important part of determining what the machine learns!\n",
    "\n",
    "    A subset of variables in the e-commerce fashion review dataset to consider for labels you could use in ML tasks include:\n",
    "        # rating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n",
    "        # recommended_ind: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n",
    "        # positive_feedback_count: Positive Integer documenting the number of other customers who found this review positive.\n",
    "\n",
    "    In this case, we are doing sentiment analysis.\n",
    "    To keep things simple, we use the rating only, and return a binary positive or negative sentiment score based on an arbitrarty cutoff.\n",
    "    \"\"\"\n",
    "    # TODO: Add your logic for the labelling function here\n",
    "    # It is up to you on what value to choose as the cut off point for the postive class\n",
    "    # A good value to start would be 4\n",
    "    # This function should return either a 0 or 1 depending on the rating of a particular row\n",
    "    if df['rating']>=4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "# final features and labels\n",
    "_has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "reviews = _has_review_df[\"review_text\"]\n",
    "labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "has_review_df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "del _has_review_df\n",
    "\n",
    "# a few checks\n",
    "assert (\n",
    "    labels.shape == reviews.shape\n",
    "), \"Labels and reviews should be equal shape vectors!\"\n",
    "assert (\n",
    "    not sum([1 if r == \"nan\" else 0 for r in reviews]) > 0\n",
    "), \"There are `nan` values in the feature set!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c20bb-0907-4c36-88fa-5dca1beca603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_positive_sentiment = labels.sum() / labels.shape[0]\n",
    "print(f\"{round(100*pct_positive_sentiment,3)}% of the labels have positive sentiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1303a4-2911-4b5b-9462-1173f900bc96",
   "metadata": {},
   "source": [
    "### Let us try to visualise the data that we just labeled depending on the rating. \n",
    "\n",
    "In a real world project, iterating at this point is crucial. You need to look through the way your data is labeled, and ensure it is aligned with your intuitive understanding and objectives of the algorithm. There are also automated tools to aid your label cleaning operations, such as [Cleanlab](https://github.com/cleanlab/cleanlab).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2b9ea-e92e-4351-a7bb-c28132a0a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "positive_color = \"green\"\n",
    "negative_color = \"red\"\n",
    "N = 10\n",
    "\n",
    "# fetch subset of data\n",
    "idxs = np.random.choice(reviews.index, 10, replace=False)\n",
    "_labels_subset = labels[idxs]\n",
    "_reviews_subset = reviews[idxs]\n",
    "\n",
    "# print each sample and color the text by sentiment\n",
    "for label, review in zip(_labels_subset, _reviews_subset):\n",
    "    color = negative_color if label == 0 else positive_color\n",
    "    print(colored(review, color), end=\"\\n\\n\")\n",
    "\n",
    "# in a real world project, iterating at this point is crucial.\n",
    "# you need to look through the way your data is labeled, and ensure it is aligned with your intuitive understanding and objectives of the algorithm.\n",
    "# there are also automated tools to aid your label cleaning operations, such as: https://github.com/cleanlab/cleanlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36115238-b8c6-4c56-8e68-e18a2a6a3728",
   "metadata": {},
   "source": [
    "### What do you think about the text and their corresponding labels? \n",
    "- Do you think the labels fit the text? \n",
    "- If not what do you think we can do to fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb56ce-67a1-4521-92c1-a874fd6470e3",
   "metadata": {},
   "source": [
    "### Filtering Stop Words\n",
    "In this part we will be filtering the stop words from the reviews. We remove stopwords in NLP datasets because there are words that do not carry much meaning on their own, and their presence can add noise to the analysis. These words are common and frequently occurring words such as \"a\", \"an\", \"the\", \"of\", and \"and\". \n",
    "\n",
    "Removing stopwords can improve the accuracy and efficiency of natural language processing tasks, such as sentiment analysis or topic modeling, by reducing the dimensionality of the data and increasing the signal-to-noise ratio. By removing these uninformative words, the resulting dataset may contain more meaningful information that can be used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f1b17-1437-4e01-aebb-fb0d8bda6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stopwords = list(nltk.corpus.stopwords.words(\"english\"))\n",
    "non_stopwords = []\n",
    "for review in reviews:\n",
    "    for word in review.split():\n",
    "        word = word.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        if word == \"\":\n",
    "            continue\n",
    "        if not word.lower() in stopwords:\n",
    "            non_stopwords.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b7659c-fb01-4aa8-8dcf-376c90703feb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Find the K most common wordsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3533c-3926-4611-a5f2-de8c0039fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 25\n",
    "words, counts = zip(*Counter(non_stopwords).most_common(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb5e9d-339b-4577-8124-9b206d157763",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "plt.xticks(rotation=55)\n",
    "ax.bar(x=words, height=counts, color=GREEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865e1be-d620-40b7-8c3d-8e79c4393943",
   "metadata": {},
   "source": [
    "### What do the other features in the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b41a43-4f62-44ea-8f7a-5ed8d8d8923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=has_review_df, hue=\"label\", corner=True, palette=sns_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb41e6-8956-458b-96ca-39dbb33b8a15",
   "metadata": {},
   "source": [
    "## Task 2: Scoping Out a Machine Learning Project\n",
    "\n",
    "As ModaMetric's newly onboarded data scientist, you're entrusted with an exciting challenge. The data science team, still in its infancy, has primarily focused on metrics and analytics that provide surface-level insights. They've yet to delve into the rich, unstructured data residing in customer reviews. And that's where you step in. Your job is to design and implement a machine learning pipeline using Metaflow capable of performing sentiment analysis on the customer reviews.\n",
    "\n",
    "As a Data Scientist, you know that a successful project requires not only technical skills but also effective project management. In this task, you will take on the role of a Data Scientist tasked with leading the development of a sentiment analysis classifier. You will be responsible for planning and executing the project, ensuring that it aligns with business goals, stays within scope, and delivers value to stakeholders.\n",
    "\n",
    "To do this, you will create a one-page document that outlines the business value of the project, its scope, how to measure and monitor success, and when to quit. This task is designed to challenge you to think holistically about the project, and to consider not only the technical details but also the broader context in which the project is situated. Good luck!\n",
    "\n",
    "Suggestion: Spend 1-2 hours on this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e193294-fc19-40ad-ba26-e20df3c7043c",
   "metadata": {},
   "source": [
    "Fill in the section below with your answers!\n",
    "\n",
    "### 1. The business value\n",
    "Diving into what customers say about our products can help us make them better and boost our brand. Analyzing these comments can show us what people like and don't like. This is key because many customers decide to buy based on reviews. Positive feedback means more sales.\n",
    "\n",
    "\n",
    "### 2. The scope\n",
    "We're building a tool to figure out if our customer feedback is positive or negative. We'll clean up and organize the feedback first. Then, using the ratings, we'll tag each comment as good or bad. We’ll test our tool to make sure it works well. Later on, we might use more advanced methods if needed.\n",
    "\n",
    "### 3. How to measure success\n",
    "How Well It Works: If our tool often gets it right, that's a good sign.\n",
    "\n",
    "Useful Insights: We want our tool to spot both good and bad feedback, even if there's way more of one kind.\n",
    "\n",
    "Real Results: If we make changes based on bad reviews and then see more good reviews, our tool is helping.\n",
    "\n",
    "What Others Think: We’ll share the results with our teams and see if they find them useful.\n",
    "    \n",
    "\n",
    "### 4. How to monitor success\n",
    "We'll regularly check how our tool is doing with new feedback. A simple chart can show us if more feedback is good or bad over time. We'll also talk to other teams in our company to see if the info helps them. Plus, we’ll check in with the people in charge to get their thoughts and improve where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164224b3-1539-4874-9725-d9fb913ffa43",
   "metadata": {},
   "source": [
    "### Great job completing Task 2! \n",
    "\n",
    "Why do you think it is important to create a one-page document prior to beginning work on the project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7ad7b-3c52-4bd9-8582-c3b05ed1bd67",
   "metadata": {},
   "source": [
    "## Task 3: Baseline Machine Learning Flow\n",
    "\n",
    "Finally, you'll develop a baseline model. This initial model, while simple, is crucial as it provides a benchmark for later, more complex models. You'll process the data, implement a basic machine learning algorithm, and evaluate its performance.\n",
    "\n",
    "Throughout this journey, you're not just a data scientist - you're a trailblazer helping ModaMetric navigate the seas of unstructured data. Ready to dive in? \n",
    "\n",
    "A basic baseline in a machine learning model is the simplest possible model that can be used to make predictions on the dataset. The basic baseline can be as simple as predicting the most frequent class for a classification problem or the mean value of the target variable for a regression problem. The purpose of establishing a baseline is to provide a benchmark for evaluating the performance of more complex models. A model that cannot outperform the basic baseline is considered to be useless and should not be used in practice.\n",
    "\n",
    "Here you will need to convert the code from above that was used to perform preprocessing and EDA on the dataset and create a Flow to run in order to train a baseline model. \n",
    "\n",
    "**NOTE:** It is important to realise that this is being run as a separate file and therefore re-using functions from above will not work. \n",
    "\n",
    "Suggestion: Spend 2-4 hours on this section. Rememeber that the more organized your earlier work is, the easier it is to write flows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded69025-d3c9-4ac7-bf43-39c447746418",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile baseline_flow.py\n",
    "from metaflow import (\n",
    "    FlowSpec,\n",
    "    step,\n",
    "    Flow,\n",
    "    current,\n",
    "    Parameter,\n",
    "    IncludeFile,\n",
    "    card,\n",
    "    current,\n",
    ")\n",
    "from metaflow.cards import Table, Markdown, Artifact\n",
    "\n",
    "# TODO move your labeling function from earlier in the notebook here\n",
    "labeling_function = lambda row: 1 if row['rating'] >= 4 else 0\n",
    "\n",
    "\n",
    "class BaselineNLPFlow(FlowSpec):\n",
    "    # We can define input parameters to a Flow using Parameters\n",
    "    # More info can be found here https://docs.metaflow.org/metaflow/basics#how-to-define-parameters-for-flows\n",
    "    split_size = Parameter(\"split-sz\", default=0.2)\n",
    "    # In order to use a file as an input parameter for a particular Flow we can use IncludeFile\n",
    "    # More information can be found here https://docs.metaflow.org/api/flowspec#includefile\n",
    "    data = IncludeFile(\"data\", default=\"../data/Womens Clothing E-Commerce Reviews.csv\")\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        # Step-level dependencies are loaded within a Step, instead of loading them\n",
    "        # from the top of the file. This helps us isolate dependencies in a tight scope.\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # load dataset packaged with the flow.\n",
    "        # this technique is convenient when working with small datasets that need to move to remove tasks.\n",
    "        df = pd.read_csv(io.StringIO(self.data))\n",
    "\n",
    "        # filter down to reviews and labels\n",
    "        df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "        df[\"review_text\"] = df[\"review_text\"].astype(\"str\")\n",
    "        _has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "        reviews = _has_review_df[\"review_text\"]\n",
    "        labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "        # Storing the Dataframe as an instance variable of the class\n",
    "        # allows us to share it across all Steps\n",
    "        # self.df is referred to as a Data Artifact now\n",
    "        # You can read more about it here https://docs.metaflow.org/metaflow/basics#artifacts\n",
    "        self.df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "        del df\n",
    "        del _has_review_df\n",
    "\n",
    "        # split the data 80/20, or by using the flow's split-sz CLI argument\n",
    "        _df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "        self.traindf, self.valdf = train_test_split(_df, test_size=self.split_size)\n",
    "        print(f\"num of rows in train set: {self.traindf.shape[0]}\")\n",
    "        print(f\"num of rows in validation set: {self.valdf.shape[0]}\")\n",
    "\n",
    "        self.next(self.baseline)\n",
    "\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "\n",
    "        # Convert the text reviews into numerical vectors using TF-IDF\n",
    "        tfidf = TfidfVectorizer()\n",
    "        train_features = tfidf.fit_transform(self.traindf[\"review\"])\n",
    "        val_features = tfidf.transform(self.valdf[\"review\"])\n",
    "\n",
    "        # Training a Logistic Regression model on the TF-IDF vectors\n",
    "        model = LogisticRegression()\n",
    "        model.fit(train_features, self.traindf[\"label\"])\n",
    "\n",
    "        # Making predictions on the validation set\n",
    "        pred = model.predict(val_features)\n",
    "\n",
    "        # Computing accuracy and ROC AUC\n",
    "        self.base_acc = accuracy_score(self.valdf[\"label\"], pred)\n",
    "        self.base_rocauc = roc_auc_score(self.valdf[\"label\"], pred)\n",
    "\n",
    "        self.next(self.end)\n",
    "\n",
    "    @card(\n",
    "        type=\"corise\"\n",
    "    )\n",
    "    @step\n",
    "    def end(self):\n",
    "        from metaflow import current\n",
    "        msg = \"Baseline Accuracy: {}\\nBaseline AUC: {}\"\n",
    "        print(msg.format(round(self.base_acc, 3), round(self.base_rocauc, 3)))\n",
    "\n",
    "        # Using assumed API functions for demonstration purposes\n",
    "        # Replace with appropriate Metaflow Cards functions if these are not correct\n",
    "\n",
    "        current.card.markdown(\"# Womens Clothing Review Results\")\n",
    "        current.card.markdown(\"## Overall Accuracy\")\n",
    "        current.card.text(f\"Accuracy: {self.base_acc:.3f}\")\n",
    "\n",
    "        false_positives = self.valdf[(pred == 1) & (self.valdf[\"label\"] == 0)]\n",
    "        current.card.markdown(\"## Examples of False Positives\")\n",
    "        current.card.table(false_positives.head())  # Displaying top 5 as an example\n",
    "\n",
    "        false_negatives = self.valdf[(pred == 0) & (self.valdf[\"label\"] == 1)]\n",
    "        current.card.markdown(\"## Examples of False Negatives\")\n",
    "        current.card.table(false_negatives.head())  # Displaying top 5 as an example\n",
    "        \n",
    "        self.next(self.end)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BaselineNLPFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f476e5-b703-4e44-ae17-04df95ac593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python baseline_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fc5ed-ec9b-4bd8-9761-aec4f8516467",
   "metadata": {},
   "source": [
    "### Great job completing Task 3!\n",
    "\n",
    "The project for Week 1 is completed but you are free to try out Task 4 below if you have the time to do so! Remember that completing Task 4 is not a requirement and completely optional. So far we have got you already building basic Machine Learning Pipelines uing Metaflow, what do you think about it so far?"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3.8 Prod (python3-prod/2)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:676633215218:image-version/python3-prod/2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
